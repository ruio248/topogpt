# config.yaml
per_device_train_batch_size: 1
gradient_accumulation_steps: 8
logging_steps: 50
learning_rate: 0.0001
remove_unused_columns: false
adam_epsilon: 0.0001
num_train_epochs: 50
save_strategy: epoch
output_dir: /work/HUGGINGFACE/model/trained_model/llama3_8b_eval_q_all
logging_dir: /work/ruioliao/topo_agent/tensorboard/dp_test
report_to: tensorboard
deepspeed: /work/ruioliao/topo_agent/train/deepspeed_config/sft_config.json



