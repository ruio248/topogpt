
## **Folder Structure**

The directory is organized as follows:

```plaintext
annotation_system/
│
├── evol_classify.py           # Classifies data quality by evolving prompts to enhance complexity
├── format_extract.py          # Extracts and structures text from unstructured outputs
├── quality_classify.py        # Evaluates the quality of outputs generated by LLMs
├── rlhf_rank_2.py             # Ranks two outputs for preference-based RLHF tasks
├── rlhf_rank_5.py             # Ranks five outputs for preference-based RLHF tasks
├── test                       # Contains test scripts and tools for evaluation
└── readme.md                  # Main documentation for the annotation system
```

---

## **Components and Purpose**

### **1. Prompt Evolution and Quality Evaluation**

- **`evol_classify.py`**  
   Enhances dataset quality by **evolving prompts**. The model rewrites prompts to make them **deeper and more complex**, effectively improving the overall data richness and suitability for advanced tasks.

- **`quality_classify.py`**  
   Evaluates the outputs of LLMs based on criteria such as **clarity**, **accuracy**, and **informativeness**. This script helps identify high-quality data for further use.

---

### **2. Text Extraction**

- **`format_extract.py`**  
   Extracts and structures specific content from verbose or unstructured outputs. This is useful for cleaning and preparing datasets for downstream tasks like model fine-tuning or evaluation.

---

### **3. Preference-Based Ranking for RLHF**

These scripts support **Reinforcement Learning with Human Feedback (RLHF)**, generating high-quality preference-based datasets for model fine-tuning:

- **`rlhf_rank_2.py`**  
   Compares and ranks **two outputs** to create preference data. This helps align models better with user expectations.  

- **`rlhf_rank_5.py`**  
   Allows ranking of **five outputs**, providing a more detailed and nuanced comparison of multiple generations from the model.

---

### **4. Testing Tools**

- **`test/`**  
   Contains scripts and tools for running tests on various components. This folder ensures the functionality of the system remains reliable and consistent.

---

## **Highlights**

- **Prompt Evolution**: Improve dataset complexity and richness through iterative prompt enhancement.
- **Quality Evaluation**: Assess and classify data outputs to identify high-quality samples.  
- **Text Structuring**: Extract meaningful information for cleaner datasets.  
- **Preference Ranking**: Generate critical preference-based feedback for RLHF.  
- **Modular Design**: Scripts are independent and can be easily integrated or extended for specific tasks.

---
